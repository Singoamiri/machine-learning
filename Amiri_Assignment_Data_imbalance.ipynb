{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**T/UDOM/2017/02595**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA IMBALANCE\n",
    "**Meaning of Data imbalance**\n",
    "Datasets in which one class is much more frequent than the other class are often called imbalanced\n",
    "datasets, or datasets with imbalanced classes. In reality, imbalanced data is the norm,\n",
    "and it is rare that the events of interest have equal or even similar frequency in the\n",
    "data.Class imbalance can be found in many different areas including medical diagnosis, spam filtering, and fraud detection.\n",
    "imbalanced data(Classes) are a common problem in machine learning classification where there are a disproportionate ratio ofobservations in each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Data Imbalance occur?**\n",
    "data imbalance occur because the machine keep the output of the inputs data even if the output is not true for all the data entered example if the data input resulted to an output that the black person is ignorant,the machine will keep the result even if there is ablack person who is not ignorant\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Data are imbalanced?**\n",
    "1.fraud detection in banking\n",
    "2.real-time bidding in marketing\n",
    "3.spam filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methods Used to Deal with Imbalanced data**\n",
    "1. Change the performance metric\n",
    "\n",
    "accuracy is not the best metric to use when evaluating imbalanced datasets as it can be very misleading. Metrics that can provide better insight include Confusion \n",
    "1.1 Matrix: a table showing correct predictions and types of incorrect predictions.\n",
    "1.2 Precision: the number of true positives divided by all positive predictions. Precision is also called Positive Predictive Value. It is a measure of a classifier’s exactness. Low precision indicates a high number of false positives.\n",
    "1.3 Recall: the number of true positives divided by the number of positive values in the test data. Recall is also called Sensitivity or the True Positive Rate. It is a measure of a classifier’s completeness. Low\n",
    "recall indicates a high number of false negatives.\n",
    "1.4 F1: Score: the weighted average of precision and recall.\n",
    "2. Change the algorithm\n",
    "\n",
    "In machine learning problem, it’s a good rule of thumb to try a variety of algorithms, it can be especially beneficial with imbalanced datasets. Decision trees frequently perform well on imbalanced data. They work by learning a hierarchy of if/else questions and this can force both classes to be addressed.\n",
    "3. Resample the training set\n",
    "\n",
    "3.1 Under-sampling: Under-sampling balances the dataset by reducing the size of the abundant class\n",
    "3.2 oversampling: is used when the quantity of data is insufficient. It tries to balance\n",
    "dataset by increasing the size of rare samples\n",
    "4. Design your own models\n",
    "\n",
    " it is possible to design many models that naturally generalize in favour of the rare class. For example, tweaking an SVM to penalize wrong classifications of the rare class by the same ratio that this class is underrepresented.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
